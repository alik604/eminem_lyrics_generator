{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "eminem_lyrics_generator - LSTM & HMM - Alik604",
      "provenance": [],
      "collapsed_sections": [
        "NnTDRtAZCt6H"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alik604/eminem_lyrics_generator/blob/master/eminem_lyrics_generator_LSTM_%26_HMM_Alik604.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8OTK5zjhteN",
        "colab_type": "text"
      },
      "source": [
        "# By Alik604\n",
        "## Adapted from https://github.com/rojagtap/eminem_lyrics_generator\n",
        "> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rS6LXXTDcH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# cd /content/drive/My Drive/Data"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7RNVjXQ-0ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnTDRtAZCt6H",
        "colab_type": "text"
      },
      "source": [
        "# Starting Preprocessing - Check point\n",
        "> This can be disreguarded as data is provided a single .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4vc42jUjCgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## retain\n",
        "\n",
        "# !pip install lyricsgenius\n",
        "# import lyricsgenius\n",
        "# genius = lyricsgenius.Genius(\"8AO32_nfbxk_8yNyBYJTnw_4qRjT2Uid1pMSW_XJ_56sBsnNLuXeKxwMMEZmQrQN\") # this is a valid key :) \n",
        "# artist = genius.search_artist(\"Eminem\", max_songs=100, sort='popularity') # XXXTENTACION \n",
        "# for i in range(100):\n",
        "#   artist.songs[i].save_lyrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R94zWarKjCm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lines = []\n",
        "# i = 1\n",
        "# for root, dirs, files in os.walk('./raw'):\n",
        "#     for file in files:\n",
        "#         if file.endswith('.json') and 'xxxtentacion' in file : # eminem  # xxxtentacion\n",
        "#             file = open(\"./raw/\" + file)\n",
        "#             json_data = file.read()\n",
        "#             data = json.loads(json_data)\n",
        "#             lines.append(data['lyrics'])\n",
        "#             i +=1\n",
        "# print(i)\n",
        "# lines = list(filter(None, lines))\n",
        "# # lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTXifyV-0aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def clean_text(sentence):\n",
        "#   sentence = sentence.lower()\n",
        "#   sentence = re.sub(r'\\[.*?\\]', \"\", sentence) # https://www.regextester.com/97589 &  https://stackoverflow.com/a/40621332\n",
        "#   sentence = re.sub(r\"\\u2005\", \"\", sentence)\n",
        "\n",
        "#   sentence = re.sub(r\"’\", \"\\'\", sentence) \n",
        "#   sentence = re.sub(r\"‘\", \"\\'\", sentence)\n",
        "#   sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
        "#   sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
        "#   sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
        "#   sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
        "#   sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
        "#   sentence = re.sub(r\"what's\", \"what is\", sentence)\n",
        "#   sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
        "#   sentence = re.sub(r\"there's\", \"there is\", sentence)\n",
        "#   sentence = re.sub(r\"who's\", \"who is\", sentence)\n",
        "#   sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
        "#   sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
        "#   sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
        "#   sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "#   sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
        "#   sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
        "#   sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
        "#   sentence = re.sub(r\"n't\", \" not\", sentence)\n",
        "#   sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
        "#   sentence = re.sub(r\"\\'bout\", \"about\", sentence)\n",
        "#   sentence = re.sub(r\"'til\", \"until\", sentence)\n",
        "#   sentence = re.sub(r\"c'mon\", \"come on\", sentence)\n",
        "#   sentence = re.sub(\"\\n\", \" \", sentence)\n",
        "\n",
        "#   sentence = re.sub(r\"\\u2005\", \"\", sentence)\n",
        "#   sentence = re.sub(\"[-*/()\\\"’‘'#/@;:<>{}`+=~|.!?,]\", \"\", sentence) # should it be:  \\'   rather than '   \n",
        "#   sentence = re.sub(r\"'\", \"\", sentence)\n",
        "#   sentence = re.sub(r\"\\t\", \"\", sentence)\n",
        "#   sentence = re.sub(r\"  \", \" \", sentence)\n",
        "#   sentence = re.sub(r\"  \", \" \", sentence)\n",
        "#   return sentence\n",
        "# lines = pd.DataFrame(lines, columns=['lines'])\n",
        "# lines.lines = lines.lines.apply(lambda line: clean_text(line))\n",
        "# lines.values\n",
        "\n",
        "# lines.to_csv('./preprocessed_data_xxxtentacion.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypQd-Umh7jEj",
        "colab_type": "text"
      },
      "source": [
        "# Starting ML - Check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggswMub774Hh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "59237937-73d9-4571-9ef0-20e9fbc02c15"
      },
      "source": [
        "# lines = pd.read_csv('https://github.com/alik604/eminem_lyrics_generator/raw/master/data/preprocessed_data_eminem.csv',index_col=0)\n",
        "lines = pd.read_csv('https://raw.githubusercontent.com/alik604/eminem_lyrics_generator/master/data/preprocessed_data_xxxtentacion.csv',index_col=0)\n",
        "\n",
        "lines.head(5)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ttto bass be the glory oh my dududu huh bubu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ayy i am like bitch who is your mans ayy cann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i think i i think i finally found a way to fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ooh ahh ahh ahh do not go do not go to sleep ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mmm baby i do not understand this you are cha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               lines\n",
              "0   ttto bass be the glory oh my dududu huh bubu ...\n",
              "1   ayy i am like bitch who is your mans ayy cann...\n",
              "2   i think i i think i finally found a way to fo...\n",
              "3   ooh ahh ahh ahh do not go do not go to sleep ...\n",
              "4   mmm baby i do not understand this you are cha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKEfXByiFq_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5841e403-6960-4c14-9f3c-fbc925a9a61e"
      },
      "source": [
        "lines.lines = lines.lines.apply(lambda line: line.split())\n",
        "lines.head(5)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ttto, bass, be, the, glory, oh, my, dududu, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ayy, i, am, like, bitch, who, is, your, mans,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[i, think, i, i, think, i, finally, found, a, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ooh, ahh, ahh, ahh, do, not, go, do, not, go,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[mmm, baby, i, do, not, understand, this, you,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               lines\n",
              "0  [ttto, bass, be, the, glory, oh, my, dududu, h...\n",
              "1  [ayy, i, am, like, bitch, who, is, your, mans,...\n",
              "2  [i, think, i, i, think, i, finally, found, a, ...\n",
              "3  [ooh, ahh, ahh, ahh, do, not, go, do, not, go,...\n",
              "4  [mmm, baby, i, do, not, understand, this, you,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8mMxFv-0a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [line[:-1] for line in lines.lines]\n",
        "y_train = [line[1:] for line in lines.lines]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6cueFD--0bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT51cTsN-0bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines.lines)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyZARYVe-0b-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f82ca845-535a-48e6-bd11-60a9ee7a0e9d"
      },
      "source": [
        "print(x_train[0])\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "y_train = tokenizer.texts_to_sequences(y_train)\n",
        "print(x_train[0])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ttto', 'bass', 'be', 'the', 'glory', 'oh', 'my', 'dududu', 'huh', 'bubu', 'ohohohoh', 'yeah', 'yeah', 'bow', 'ohohohoh', 'yeah', 'blat', 'blat', 'ohohohoh', 'yeah', 'yeah', 'oh', 'my', 'dududu', 'blat', 'ohohohoh', 'yeah', 'yeah', 'uh', 'yeah', 'yeah', 'uh', 'sauce', 'on', 'ya', 'nigga', 'got', 'the', 'sauce', 'on', 'me', 'i', 'got', 'sauce', 'boss', 'like', 'a', 'young', 'nigga', 'was', 'ross', 'on', 'me', 'like', 'i', 'am', 'fucking', 'ross', 'pull', 'up', 'on', 'your', 'shawty', 'i', 'put', 'sauce', 'on', 'it', 'like', 'i', 'fucking', 'spilled', 'sauce', 'on', 'ya', 'nigga', 'got', 'the', 'sauce', 'on', 'me', 'like', 'i', 'fucking', 'killed', 'huh', 'do', 'not', 'be', 'alarmed', 'this', 'is', 'just', 'for', 'fun', 'you', 'know', 'what', 'the', 'fuck', 'i', 'am', 'saying', 'ayy', 'ayy', 'ayy', 'it', 'is', 'a', 'carnival', 'ride', 'yeah', 'yeah', 'yeah', 'oh', 'my', 'oh', 'my', 'oh', 'my', 'oh', 'my', 'yuh', 'all', 'them', 'fancy', 'cunts', 'said', 'they', 'wanna', 'bring', 'me', 'home', 'yeah', 'shawty', 'why', 'you', 'stalling', 'are', 'you', 'gonna', 'give', 'me', 'dome', 'yeah', 'uh', 'i', 'am', 'not', 'disrespectful', 'i', 'just', 'really', 'wanna', 'cum', 'yeah', 'yeah', 'i', 'do', 'not', 'wanna', 'talk', 'yeah—', 'oh', 'my', 'oh', 'my', 'question', 'one', 'what', 'she', 'ask', 'me', 'yeah', 'pull', 'up', 'uh', 'with', 'two', 'white', 'bitches', 'marykate', 'ashley', 'oh', 'my', 'yuh', 'yeah', 'yeah', 'yeah', 'yeah', 'they', 'gong', 'smash', 'me', 'yeah', 'if', 'they', 'talk', 'too', 'much', 'i', 'am', 'gonna', 'fuck', 'around', 'and', 'pass', 'em', 'sauce', 'on', 'ya', 'nigga', 'got', 'the', 'sauce', 'on', 'me', 'i', 'got', 'sauce', 'boss', 'like', 'a', 'young', 'nigga', 'was', 'ross', 'on', 'me', 'like', 'i', 'am', 'fucking', 'ross', 'pull', 'up', 'on', 'your', 'shawty', 'i', 'put', 'sauce', 'on', 'it', 'like', 'i', 'fucking', 'spilled', 'sauce', 'on', 'ya', 'nigga', 'got', 'the', 'sauce', 'on', 'me', 'like', 'i', 'fucking', 'killed', 'huh', 'woah', 'huh', 'ohohohoh', 'yeah', 'oh', 'my', 'ohohohoh', 'yeah', 'ohohohoh', 'yeah', 'ohohohoh', 'yeah', 'yeah', 'bow', 'ohohohoh', 'yeah', 'blat', 'blaow', 'ohohohoh', 'yeah', 'oh', 'my', 'blaow', 'ohohohoh', 'yeah', 'yeah', 'uh', 'sauce', 'on', 'ya', 'nigga', 'got', 'the', 'sauce', 'on', 'me', 'uh', 'boss', 'like', 'a', 'young', 'nigga', 'was', 'ross', 'on', 'me', 'uh', 'pull', 'up', 'on', 'your', 'shawty', 'i', 'put', 'sauce', 'on', 'it', 'yuh', 'sauce', 'on', 'ya', 'nigga', 'got', 'the', 'sauce', 'on', 'me', 'yeah']\n",
            "[973, 974, 31, 2, 672, 44, 4, 673, 63, 975, 186, 20, 20, 674, 186, 20, 432, 432, 186, 20, 20, 44, 4, 673, 432, 186, 20, 20, 55, 20, 20, 55, 117, 14, 250, 38, 34, 2, 117, 14, 11, 1, 34, 117, 516, 17, 6, 172, 38, 47, 378, 14, 11, 17, 1, 7, 57, 378, 187, 16, 14, 19, 93, 1, 87, 117, 14, 12, 17, 1, 57, 675, 117, 14, 250, 38, 34, 2, 117, 14, 11, 17, 1, 57, 676, 63, 9, 5, 31, 976, 33, 13, 43, 39, 677, 3, 42, 35, 2, 36, 1, 7, 517, 28, 28, 28, 12, 13, 6, 977, 433, 20, 20, 20, 44, 4, 44, 4, 44, 4, 44, 4, 124, 27, 241, 978, 979, 114, 77, 32, 434, 11, 251, 20, 93, 45, 3, 980, 48, 3, 285, 67, 11, 981, 20, 55, 1, 7, 5, 982, 1, 43, 88, 32, 518, 20, 20, 1, 9, 5, 32, 252, 983, 44, 4, 44, 4, 242, 64, 35, 37, 286, 11, 20, 187, 16, 55, 24, 203, 188, 435, 984, 985, 44, 4, 124, 20, 20, 20, 20, 77, 85, 204, 11, 20, 79, 77, 252, 189, 164, 1, 7, 285, 36, 253, 10, 678, 128, 117, 14, 250, 38, 34, 2, 117, 14, 11, 1, 34, 117, 516, 17, 6, 172, 38, 47, 378, 14, 11, 17, 1, 7, 57, 378, 187, 16, 14, 19, 93, 1, 87, 117, 14, 12, 17, 1, 57, 675, 117, 14, 250, 38, 34, 2, 117, 14, 11, 17, 1, 57, 676, 63, 129, 63, 186, 20, 44, 4, 186, 20, 186, 20, 186, 20, 20, 674, 186, 20, 432, 519, 186, 20, 44, 4, 519, 186, 20, 20, 55, 117, 14, 250, 38, 34, 2, 117, 14, 11, 55, 516, 17, 6, 172, 38, 47, 378, 14, 11, 55, 187, 16, 14, 19, 93, 1, 87, 117, 14, 12, 124, 117, 14, 250, 38, 34, 2, 117, 14, 11, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JivHjswYQqsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx = tokenizer.word_index\n",
        "idx2word = {value: key for key, value in word2idx.items()}"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gc1P4IYWlDzV",
        "colab": {}
      },
      "source": [
        "word2idx[\"<pad>\"] = 0\n",
        "idx2word[0] = \"<pad>\""
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYmlGZ8E-0cQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "6e1988b3-20a8-4471-ca04-1cb9fdb3180c"
      },
      "source": [
        "lengths = [len(sequence) for sequence in x_train]\n",
        "\n",
        "lengths = pd.Series(lengths)\n",
        "lengths.describe()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     56.000000\n",
              "mean     258.339286\n",
              "std      164.577064\n",
              "min       44.000000\n",
              "25%      141.000000\n",
              "50%      235.000000\n",
              "75%      332.250000\n",
              "max      992.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY_uinnF-0co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 256#1024 # None to Infer it \n",
        "# maxlen: Optional Int, maximum length of all sequences. If not provided, sequences will be padded to the length of the longest individual sequence\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen, padding='pre', truncating='pre') # prehaps pre is ideal: https://stackoverflow.com/a/51825971\n",
        "y_train = pad_sequences(y_train, maxlen=maxlen, padding='pre', truncating='pre')"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8GkHpsH-0c4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7edbaaa-67aa-477c-e106-3b74004b5c34"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import GRU, LSTM, Dense, Input, Embedding, Dropout, Bidirectional \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11450"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaEAkQ1T-0dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1 # 8526 for eminem; ~2000 for X\n",
        "embedding_dim = 128 #1024 # 128\n",
        "bridge = int(vocab_size/3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True))\n",
        "model.add((LSTM(embedding_dim, return_sequences=True)))\n",
        "\n",
        "# model.add(Dense(embedding_dim)) # I found this to work well in LSTMs for regression\n",
        "# model.add(Bidirectional(LSTM(embedding_dim, return_sequences=True)))\n",
        "\n",
        "model.add(Dense(vocab_size))\n",
        "\n",
        "opt = Adam(learning_rate=0.001) # 0.001 is default # 00025\n",
        "best = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='loss', mode='min')\n",
        "\n",
        "model.compile(optimizer=opt, loss=SparseCategoricalCrossentropy(from_logits=True)) # normally, I would have this set to false, and have my output layer have h <- sigmoid; were h is the activation function\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-afmZUd-0dL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7ed7a64-7c7d-4ed2-e808-59b18baa3120"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=1, verbose=1, callbacks=[best], validation_split=0.1).history # loss should be < 2.0. keep reruning as needed"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 1s/step - loss: 5.9163 - val_loss: 5.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF9Z5xlkQ3Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model_biListm_X_pre.h5\")\n",
        "#model = load_model(\"model.h5\")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrchgcJv-0dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(word):\n",
        "    # word = clean_text(word)\n",
        "    inputs = np.zeros((1, 1))\n",
        "    inputs[0, 0] = word2idx[word]\n",
        "    count = 1\n",
        "    while count <= 50:\n",
        "        pred = model.predict(inputs)\n",
        "        word = np.argmax(pred)\n",
        "        if word >= vocab_size:\n",
        "            word = vocab_size - 1\n",
        "\n",
        "        inputs[0, 0] = word\n",
        "        \n",
        "        print(idx2word[word], end=\" \")\n",
        "        count += 1\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQoTjmtY-0dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f7a3da35-59cf-4e97-d059-8230fbe5dbe6"
      },
      "source": [
        "generate(\"look\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never want no my but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too but too "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWoOF4cwkp3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "4a23cff6-b662-4d0d-e934-4fff4ded7a78"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(history['loss'])), history['loss'])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7eff53943f98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPYklEQVR4nO3dfYxldX3H8fdHt1hZkQUZ1ocVF01FsClCJ1gSglJaHkwoavnD1hSLks2mxLY2NtLaNFb7h0qbiqEy2WDRpqC2q5uatN2CtoamKu0gqyAPsi4ou0oZxAfEKAW+/eOerZfLnZmzM3d2dn+8X8nNPef8vnPu97eTfPbkPNxJVSFJOvg9bbUbkCRNhoEuSY0w0CWpEQa6JDXCQJekRqxZrQ8+6qijauPGjav18ZJ0ULrpppseqKqpcWOrFugbN25kdnZ2tT5ekg5KSb4x35inXCSpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqRG9Aj3JuiRbk9yR5PYkp46MvzHJV5LckuTzSU5cmXYlSfPp++j/5cD2qrogySHAoSPjdwOvqqrvJjkX2AK8coJ9SpIWsWigJzkcOB34bYCqegR4ZLimqj4/tPpFYMPkWpQk9dHnlMuxwBxwdZKbk1yVZO0C9W8B/mXcQJJNSWaTzM7NzS2hXUnSfPoE+hrgZODKqjoJeBi4dFxhkjMYBPo7xo1X1Zaqmq6q6ampsd/+KElaoj6BvhvYXVU3dutbGQT8EyT5BeAq4Pyq+s7kWpQk9bFooFfVfcC9SY7rNp0J3DZck+QY4FPAb1XV1ybepSRpUX3vcnkrcE13h8su4KIkmwGqagb4U+A5wIeSADxaVdMr0K8kaR69Ar2qdgCjAT0zNH4xcPEE+5Ik7SOfFJWkRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRvQK9CTrkmxNckeS25OcOjL+siRfSPKTJG9fmVYlSQtZ07PucmB7VV2Q5BDg0JHxB4HfBV47yeYkSf0teoSe5HDgdODDAFX1SFV9b7imqu6vqv8G/ndFupQkLarPKZdjgTng6iQ3J7kqydqlfFiSTUlmk8zOzc0tZReSpHn0CfQ1wMnAlVV1EvAwcOlSPqyqtlTVdFVNT01NLWUXkqR59An03cDuqrqxW9/KIOAlSQeQRQO9qu4D7k1yXLfpTOC2Fe1KkrTP+t7l8lbgmu4Ol13ARUk2A1TVTJLnArPAs4HHk/w+cEJV/WAlmpYkPVmvQK+qHcD0yOaZofH7gA0T7EuStI98UlSSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktSIXoGeZF2SrUnuSHJ7klNHxpPkg0l2JvlKkpNXpl1J0nzW9Ky7HNheVRckOQQ4dGT8XODnutcrgSu7d0nSfrLoEXqSw4HTgQ8DVNUjVfW9kbLzgb+tgS8C65I8b+LdSpLm1eeUy7HAHHB1kpuTXJVk7UjNC4B7h9Z3d9ueIMmmJLNJZufm5pbctCTpyfoE+hrgZODKqjoJeBi4dCkfVlVbqmq6qqanpqaWsgtJ0jz6BPpuYHdV3ditb2UQ8MP2AC8cWt/QbZMk7SeLBnpV3Qfcm+S4btOZwG0jZZ8GLuzudvkl4PtV9e3JtipJWkjfu1zeClzT3eGyC7goyWaAqpoB/hl4DbAT+BFw0Qr0KklaQK9Ar6odwPTI5pmh8QIumWBfkqR95JOiktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRqzpU5TkHuAh4DHg0aqaHhk/Avgb4CXAj4E3V9Wtk21VkrSQXoHeOaOqHphn7I+BHVX1uiQvA/4aOHPZ3UmSepvUKZcTgH8DqKo7gI1J1k9o35KkHvoGegHXJbkpyaYx418GXg+Q5BTgRcCGybQoSeqj7ymX06pqT5KjgeuT3FFVNwyNvxe4PMkO4BbgZgbn25+g+89gE8AxxxyzvM4lSU/Q6wi9qvZ07/cD24BTRsZ/UFUXVdUrgAuBKWDXmP1sqarpqpqemppadvOSpJ9aNNCTrE1y2N5l4Czg1pGadUkO6VYvBm6oqh9MullJ0vz6nHJZD2xLsrf+2qranmQzQFXNAMcDH01SwFeBt6xQv5KkeSwa6FW1CzhxzPaZoeUvAC+dbGuSpH3hk6KS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1Ig1fYqS3AM8BDwGPFpV0yPjhwN/BxzT7fMvqurqybYqSVpIr0DvnFFVD8wzdglwW1Wdl2QKuDPJNVX1yPJblCT1MalTLgUcliTAs4AHgUcntG9JUg99A72A65LclGTTmPErgOOBbwG3AL9XVY+PFiXZlGQ2yezc3NySm5YkPVnfQD+tqk4GzgUuSXL6yPjZwA7g+cArgCuSPHt0J1W1paqmq2p6ampqOX1Lkkb0CvSq2tO93w9sA04ZKbkI+FQN7ATuBl42yUYlSQtbNNCTrE1y2N5l4Czg1pGybwJndjXrgeOAXZNtVZK0kD53uawHtg2ud7IGuLaqtifZDFBVM8B7gI8kuQUI8I4F7oiRJK2ARQO9qnYBJ47ZPjO0/C0GR+6SpFXik6KS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGrOlTlOQe4CHgMeDRqpoeGf9D4I1D+zwemKqqByfXqiRpIb0CvXNGVT0wbqCqLgMuA0hyHvA2w1yS9q+VOOXyG8DHVmC/kqQF9A30Aq5LclOSTfMVJTkUOAf45Dzjm5LMJpmdm5vb924lSfPqG+inVdXJwLnAJUlOn6fuPOA/5zvdUlVbqmq6qqanpqaW0K4kaT69Ar2q9nTv9wPbgFPmKX0Dnm6RpFWxaKAnWZvksL3LwFnArWPqDgdeBfzjpJuUJC2uz10u64FtSfbWX1tV25NsBqiqma7udcB1VfXwinQqSVrQooFeVbuAE8dsnxlZ/wjwkUk1JknaNz4pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNWNOnKMk9wEPAY8CjVTU9pubVwAeAnwEeqKpXTa5NSdJiegV654yqemDcQJJ1wIeAc6rqm0mOnkh3kqTeJnXK5TeBT1XVNwGq6v4J7VeS1FPfQC/guiQ3Jdk0ZvylwBFJPtfVXDhuJ0k2JZlNMjs3N7fUniVJY/Q95XJaVe3pTqVcn+SOqrphZD+/CJwJPBP4QpIvVtXXhndSVVuALQDT09O1/PYlSXv1OkKvqj3d+/3ANuCUkZLdwL9W1cPdefYbgBMn2agkaWGpWvhAOcla4GlV9VC3fD3w7qraPlRzPHAFcDZwCPBfwBuq6tYF9jsHfGP5U9jvjgLGXhxumHNu31NtvnDwzvlFVTU1bqDPKZf1wLYke+uvrartSTYDVNVMVd2eZDvwFeBx4KqFwrz7ubENHeiSzI67bbNlzrl9T7X5QptzXjTQq2oXY06fVNXMyPplwGWTa02StC98UlSSGmGg77stq93AKnDO7XuqzRcanPOiF0UlSQcHj9AlqREGuiQ1wkAfI8mRSa5Pclf3fsQ8dW/qau5K8qYx459OsuDtmweK5cw5yaFJ/inJHUm+muS9+7f7/pKck+TOJDuTXDpm/BlJPtGN35hk49DYH3Xb70xy9v7sezmWOuckv9p9lcct3fsv7+/el2o5v+du/JgkP0zy9v3V80RUla+RF/B+4NJu+VLgfWNqjgR2de9HdMtHDI2/HrgWuHW157PScwYOZfBtnDB4sOw/gHNXe05j+n868HXgxV2fXwZOGKn5HWCmW34D8Ilu+YSu/hnAsd1+nr7ac1rhOZ8EPL9b/nlgz2rPZ6XnPDS+FfgH4O2rPZ99eXmEPt75wEe75Y8Crx1TczZwfVU9WFXfZfAE7TkASZ4F/AHw5/uh10lZ8pyr6kdV9e8AVfUI8CVgw37oeV+dAuysql1dnx9nMO9hw/8OW4EzM3iq7nzg41X1k6q6G9jJk78C40C05DlX1c1V9a1u+1eBZyZ5xn7penmW83smyWuBuxnM+aBioI+3vqq+3S3fx+Bp2VEvAO4dWt/dbQN4D/CXwI9WrMPJW+6cgf//bvzzgM+uRJPLtGj/wzVV9SjwfeA5PX/2QLScOQ/7deBLVfWTFepzkpY85+5g7B3An+2HPiduX/7ARVOSfAZ47pihdw6vVFUl6X1vZ5JXAC+pqreNnpdbbSs156H9rwE+BnywBk8YqwFJXg68DzhrtXvZD94F/FVV/bA7YD+oPGUDvap+Zb6xJP+T5HlV9e0kzwPG/cGOPcCrh9Y3AJ8DTgWmuz/btwY4OsnnqurVrLIVnPNeW4C7quoDE2h3JewBXji0vqHbNq5md/cf1OHAd3r+7IFoOXMmyQYG37B6YVV9feXbnYjlzPmVwAVJ3g+sAx5P8uOqumLl256A1T6JfyC+GHwnzfAFwvePqTmSwXm2I7rX3cCRIzUbOXguii5rzgyuF3ySwTdzrvp85pnjGgYXco/lpxfLXj5ScwlPvFj2993yy3niRdFdHBwXRZcz53Vd/etXex77a84jNe/iILsouuoNHIgvBucPPwvcBXxmKLSmGXyT5N66NzO4OLYTuGjMfg6mQF/ynBkcARVwO7Cje1282nOaZ56vAb7G4C6Id3bb3g38Wrf8swzubtjJ4GugXzz0s+/sfu5ODsC7eCY9Z+BPgIeHfqc7gKNXez4r/Xse2sdBF+g++i9JjfAuF0lqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGvF/CFcAg3xrJLcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU17FZhR_-j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "60b8cab0-35e3-4e74-e738-ebf0eb59ec52"
      },
      "source": [
        "!pip install hmmlearn\n",
        "from hmmlearn.hmm import MultinomialHMM\n",
        "print(len(tokenizer.word_index)) # vocab size? \n",
        "x_train.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hmmlearn in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.16.0)\n",
            "2030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9KiixB0_-_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "81cf3360-9f96-4f64-81ed-809f861ca3d6"
      },
      "source": [
        "hmm = MultinomialHMM(n_components=10, n_iter = 100) # covariance_type=\"full\"\n",
        "hmm.fit(x_train) # max: 60000"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting a model with 20389 free scalar parameters with only 14336 data points will result in a degenerate solution.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=10,\n",
              "               n_iter=50, params='ste',\n",
              "               random_state=RandomState(MT19937) at 0x7F0006089888,\n",
              "               startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
              "               verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDB9wpNvEtcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "59482207-52c3-4846-b1fc-7775c319ed0c"
      },
      "source": [
        "generated, y  = hmm.sample(20)  # np.array([1,2,3]).reshape(-1, 1)\n",
        "generated = generated.flatten()\n",
        "print(generated)\n",
        "\n",
        "for pred in generated:\n",
        "  print(idx2word[pred], end =' ')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 945    6  105    1  123    3   28 1984   68   19   51   51   50  349\n",
            "  616 1029  195  406   12  385]\n",
            "endz a how i going you ayy watched mind your cause cause at name truth constantly god another it peace "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehvRLYh_E-ES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f7eaf24f-bcef-44e6-fe48-2623c4fa39c3"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_train.flatten().shape)\n",
        "\n",
        "hmm = MultinomialHMM(n_components=10, n_iter = 300) # covariance_type=\"full\"\n",
        "hmm.fit(x_train.flatten().reshape(-1, 1)) # max: 60000"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting a model with 20389 free scalar parameters with only 14336 data points will result in a degenerate solution.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(56, 256)\n",
            "(14336,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=10,\n",
              "               n_iter=500, params='ste',\n",
              "               random_state=RandomState(MT19937) at 0x7F0006089888,\n",
              "               startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
              "               verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqCOAZUpXfBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0f789e9b-1c11-4639-9220-518005c59d99"
      },
      "source": [
        "generated, y = hmm.sample(20)  # np.array([1,2,3]).reshape(-1, 1)\n",
        "generated = generated.flatten()\n",
        "print(generated)\n",
        "for pred in generated:\n",
        "  print(idx2word[pred], end =' ')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  20   94  204  246   11    1   14   51    2   54  316   14 1661  552\n",
            "    8    1   38  616    6 1258]\n",
            "yeah shit smash mood me i on cause the when bled on enemy flights in i nigga truth a ops "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP6wGzQ4FbMI",
        "colab_type": "text"
      },
      "source": [
        "#### Debuging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIrKHW4WHswT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "795ec20e-86a7-46ac-8664-43c9a8c893b7"
      },
      "source": [
        "word = 'if' #clean_text(word)\n",
        "inputs = np.zeros((1, 1))\n",
        "inputs[0, 0] = word2idx[word]\n",
        "count = 1\n",
        "while count <= 50:\n",
        "    pred = model.predict(inputs)\n",
        "    word = np.argmax(pred)\n",
        "    if word >= vocab_size:\n",
        "        word = vocab_size - 1\n",
        "\n",
        "    inputs[0, 0] = word\n",
        "    \n",
        "    print(idx2word[word], end=\" \")\n",
        "    count += 1"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "well na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DARIusabIPMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = np.zeros((1, 1))\n",
        "inputs[0, 0] = word2idx['at']\n",
        "\n",
        "# inputs\n",
        "pred = model.predict(inputs)\n",
        "word = np.argmax(pred)\n",
        "idx2word[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiUjR9_5ISUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MEYhwBSI0eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXDKZU3jI1EJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dslqwWTkb111",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OHpZuGwb_1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}