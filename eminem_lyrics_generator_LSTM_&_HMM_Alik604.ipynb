{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "eminem_lyrics_generator - LSTM & HMM - Alik604",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8OTK5zjhteN"
      },
      "source": [
        "# By Alik604\n",
        "## Adapted from https://github.com/rojagtap/eminem_lyrics_generator\n",
        "> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rS6LXXTDcH6"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# cd /content/drive/My Drive/Data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-w3FB4me4mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39624c4-788f-402e-86bc-d2ee0e86935c"
      },
      "source": [
        "# %%capture\r\n",
        "\r\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "!unzip -q glove.6B.zip "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[glove.6B.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
            "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7RNVjXQ-0ZK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import requests\n",
        "import codecs\n",
        "\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiYr_EWi4HkT"
      },
      "source": [
        "def clean_text(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(r'\\[*?\\]', \"\", sentence) # \\[.*?\\] # https://www.regextester.com/97589 &  https://stackoverflow.com/a/40621332\n",
        "  sentence = re.sub(r'\\[0-9]', \"\", sentence)\n",
        "\n",
        "  sentence = re.sub(r\"\\u2005\", \"\", sentence)\n",
        "\n",
        "  sentence = re.sub(r\"’\", \"\\'\", sentence) \n",
        "  sentence = re.sub(r\"‘\", \"\\'\", sentence)\n",
        "  sentence = re.sub(r\"”\", \"\\'\", sentence) \n",
        "  sentence = re.sub(r\"“\", \"\\'\", sentence)\n",
        "\n",
        "  sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
        "  sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
        "  sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
        "  sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
        "  sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
        "  sentence = re.sub(r\"what's\", \"what is\", sentence)\n",
        "  sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
        "  sentence = re.sub(r\"there's\", \"there is\", sentence)\n",
        "  sentence = re.sub(r\"who's\", \"who is\", sentence)\n",
        "  sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
        "  sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
        "  sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
        "  sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "  sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
        "  sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
        "  sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
        "  sentence = re.sub(r\"n't\", \" not\", sentence)\n",
        "  sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
        "  sentence = re.sub(r\"\\'bout\", \"about\", sentence)\n",
        "  sentence = re.sub(r\"'til\", \"until\", sentence)\n",
        "  sentence = re.sub(r\"c'mon\", \"come on\", sentence)\n",
        "  sentence = re.sub(\"\\n\", \" \", sentence)\n",
        "\n",
        "  sentence = re.sub(r\"\\u2005\", \"\", sentence)\n",
        "  sentence = re.sub(\"[-*/()\\\"’‘'#/@;:<>{}`+=~|!?,]\", \"\", sentence) # should it be:  \\'   rather than '   # TODO note: removed . \n",
        "  sentence = re.sub(r\"'\", \"\", sentence)\n",
        "  sentence = re.sub(r\"\\t\", \"\", sentence)\n",
        "  sentence = re.sub(r\"\\r\", \"\", sentence)\n",
        "  sentence = re.sub(r\"\\n\", \"\", sentence)\n",
        "\n",
        "  sentence = re.sub(r\"  \", \" \", sentence)\n",
        "  sentence = re.sub(r\"  \", \" \", sentence)\n",
        "  sentence = re.sub(r\"  \", \" \", sentence)\n",
        "\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnTDRtAZCt6H"
      },
      "source": [
        "# Starting Preprocessing - Check point\n",
        "> This can be disreguarded as data is provided a single .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4vc42jUjCgg"
      },
      "source": [
        "## retain\n",
        "\n",
        "# !pip install lyricsgenius\n",
        "# import lyricsgenius\n",
        "# genius = lyricsgenius.Genius(\"8AO32_nfbxk_8yNyBYJTnw_4qRjT2Uid1pMSW_XJ_56sBsnNLuXeKxwMMEZmQrQN\") # this is a valid key :) \n",
        "# artist = genius.search_artist(\"Eminem\", max_songs=100, sort='popularity') # XXXTENTACION \n",
        "# for i in range(100):\n",
        "#   artist.songs[i].save_lyrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R94zWarKjCm1"
      },
      "source": [
        "# lines = []\n",
        "# i = 1\n",
        "# for root, dirs, files in os.walk('./raw'):\n",
        "#     for file in files:\n",
        "#         if file.endswith('.json') and 'xxxtentacion' in file : # eminem  # xxxtentacion\n",
        "#             file = open(\"./raw/\" + file)\n",
        "#             json_data = file.read()\n",
        "#             data = json.loads(json_data)\n",
        "#             lines.append(data['lyrics'])\n",
        "#             i +=1\n",
        "# print(i)\n",
        "# lines = list(filter(None, lines))\n",
        "# # lines\n",
        "\n",
        "\n",
        "# lines = pd.DataFrame(lines, columns=['lines'])\n",
        "# lines.lines = lines.lines.apply(lambda line: clean_text(line))\n",
        "# lines.values\n",
        "\n",
        "# lines.to_csv('./preprocessed_data_xxxtentacion.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypQd-Umh7jEj"
      },
      "source": [
        "# Starting ML - Check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggswMub774Hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e34f84f-083b-4104-9a80-688f37eea006"
      },
      "source": [
        "## More books http://www.glozman.com/textpages.html\n",
        "\n",
        "\n",
        "## Eminem\n",
        "# lines = pd.read_csv('https://github.com/alik604/eminem_lyrics_generator/raw/master/data/preprocessed_data_eminem.csv',index_col=0)\n",
        "\n",
        "## XXXTentacion\n",
        "# lines = pd.read_csv('https://raw.githubusercontent.com/alik604/eminem_lyrics_generator/master/data/preprocessed_data_xxxtentacion.csv',index_col=0)\n",
        "\n",
        "## Treasure Island\n",
        "# raw_text_lower = requests.get(\"https://data.heatonresearch.com/data/t81-558/text/treasure_island.txt\").text.lower()\n",
        "# processed_text = re.sub(r'[^\\x00-\\x7f]',r'', raw_text_lower)\n",
        "# processed_text = clean_text(processed_text)\n",
        "# # processed_text\n",
        "# lines = pd.DataFrame(processed_text.split(\".\")[270:], columns=[\"lines\"])\n",
        "# print(lines.shape)\n",
        "# lines.drop_duplicates(inplace=True)\n",
        "# print(lines.shape)\n",
        "\n",
        "\n",
        "# Harry Potter books \n",
        "\n",
        "!git clone https://github.com/formcept/whiteboard.git\n",
        "# !ls whiteboard/nbviewer/notebooks/data/harrypotter\n",
        "\n",
        "DIR = \"whiteboard/nbviewer/notebooks/data/harrypotter\"\n",
        "\n",
        "temp = \"\"\n",
        "t = \"\"\n",
        "chars = []\n",
        "for book in os.listdir(DIR):\n",
        "    print(\"Reading \", book)\n",
        "    with codecs.open(DIR + '/' + book, \"rb\", \"utf-8\") as infile:\n",
        "        temp += infile.read()\n",
        "        chars.append(len(temp))\n",
        "        print(\"Characters read so far \" + str(len(temp)))\n",
        "\n",
        "processed_text = temp\n",
        "processed_text = processed_text.replace('Harry Potter and the Philosophers Stone - J.K. Rowling', '')\n",
        "processed_text = processed_text.replace('Harry Potter and the Chamber of Secrets - J.K. Rowling ', '')\n",
        "processed_text = processed_text.replace('Harry Potter and the Prisoner of Azkaban - J.K. Rowling ', '')\n",
        "processed_text = processed_text.replace('Harry Potter and the Goblet of Fire - J.K. Rowling ', '')\n",
        "processed_text = processed_text.replace('Harry Potter and the Order of the Phoenix -J.K. Rowling', '')\n",
        "processed_text = processed_text.replace('Harry Potter and the Half Blood Prince - J.K. Rowling', '')\n",
        "processed_text = processed_text.replace('Harry Potter and the Deathly Hallows - J.K. Rowling', '')\n",
        "processed_text = processed_text.replace('\\nJ ', '').replace(' K ', '').replace(' R O W L ! N G \\n\\nHARRY \\n\\nPOTTER', '').replace('Rowling', '')#.replace('Harry Potter and the', '')# .replace('Page | ', '')  \n",
        "processed_text = clean_text(processed_text)\n",
        "print(len(temp), ' char count to: ', len(processed_text))\n",
        "\n",
        "lines = pd.DataFrame(processed_text.split(\".\"), columns=[\"lines\"])\n",
        "print('pre drop_duplicates', lines.shape)\n",
        "lines = lines.apply(lambda x: x.str.strip()) \n",
        "lines.drop_duplicates(inplace=True)\n",
        "print('post drop_duplicates', lines.shape)\n",
        "\n",
        "\n",
        "lines.head(5).values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'whiteboard'...\n",
            "remote: Enumerating objects: 173, done.\u001b[K\n",
            "remote: Total 173 (delta 0), reused 0 (delta 0), pack-reused 173\u001b[K\n",
            "Receiving objects: 100% (173/173), 27.92 MiB | 31.25 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "Reading  Book 3 - The Prisoner of Azkaban.txt\n",
            "Characters read so far 676978\n",
            "Reading  Book 2 - The Chamber of Secrets.txt\n",
            "Characters read so far 1208686\n",
            "Reading  Book 5 - The Order of the Phoenix.txt\n",
            "Characters read so far 2817449\n",
            "Reading  Book 6 - The Half Blood Prince.txt\n",
            "Characters read so far 3876471\n",
            "Reading  Book 1 - The Philosopher's Stone.txt\n",
            "Characters read so far 4350900\n",
            "Reading  Book 7 - The Deathly Hallows.txt\n",
            "Characters read so far 5577924\n",
            "Reading  Book 4 - The Goblet of Fire.txt\n",
            "Characters read so far 6765174\n",
            "6765174  char count to:  6176095\n",
            "pre drop_duplicates (90178, 1)\n",
            "post drop_duplicates (68110, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['owl post harry potter was a highly unusual boy in many ways'],\n",
              "       ['for one thing he hated the summer holidays more than any other time of year'],\n",
              "       ['for another he really wanted to do his homework but was forced to do it in secret in the dead of night'],\n",
              "       ['and he also happened to be a wizard'],\n",
              "       ['it was nearly midnight and he was lying on his stomach in bed the blankets drawn right over his head like a tent a flashlight in one hand and a large leatherbound book a history of magic by bathilda bagshot propped open against the pillow']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr6ZoicXEvGE"
      },
      "source": [
        "MINWORDCOUNT = 5\r\n",
        "garbageRemover = lambda x: len(x.split(' '))\r\n",
        "lines = lines[lines['lines'].map(garbageRemover) >= MINWORDCOUNT]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8mMxFv-0a5"
      },
      "source": [
        "# x_train = [line[:-1] for line in lines.lines]\n",
        "# y_train = [line[1:] for line in lines.lines]\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# c = 0 \n",
        "for line in lines.lines:\n",
        "    tmp = line.split(' ')\n",
        "    x_train.append((\" \".join(tmp[:-1])))\n",
        "    y_train.append(tmp[-1])\n",
        "    \n",
        "    # c +=1 \n",
        "    # if c == 1:\n",
        "    #   break\n",
        "# print(x_train)\n",
        "# print(y_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2FmgybMCfLb",
        "outputId": "72419073-3a3d-4cc2-86b2-c1211ed98bfb"
      },
      "source": [
        "print(x_train[:5])\r\n",
        "print(y_train[:5])\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['owl post harry potter was a highly unusual boy in many', 'for one thing he hated the summer holidays more than any other time of', 'for another he really wanted to do his homework but was forced to do it in secret in the dead of', 'and he also happened to be a', 'it was nearly midnight and he was lying on his stomach in bed the blankets drawn right over his head like a tent a flashlight in one hand and a large leatherbound book a history of magic by bathilda bagshot propped open against the']\n",
            "['ways', 'year', 'night', 'wizard', 'pillow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6cueFD--0bb"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT51cTsN-0bm"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines.lines)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyZARYVe-0b-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c2fcc1-89db-4db9-9539-ec1468e90647"
      },
      "source": [
        "print(x_train[0])\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "y_train = tokenizer.texts_to_sequences(y_train)\n",
        "print(x_train[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "owl post harry potter was a highly unusual boy in many\n",
            "[494, 1612, 7, 75, 8, 6, 1224, 2247, 265, 14, 286]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JivHjswYQqsD"
      },
      "source": [
        "word2idx = tokenizer.word_index\n",
        "idx2word = {value: key for key, value in word2idx.items()}\n",
        "\n",
        "word2idx[\"<pad>\"] = 0\n",
        "idx2word[0] = \"<pad>\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYmlGZ8E-0cQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee235f7-bc5e-45ad-bd07-0172a2d4a8da"
      },
      "source": [
        "lengths = [len(sequence) for sequence in x_train]\n",
        "\n",
        "lengths = pd.Series(lengths)\n",
        "lengths.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    61545.000000\n",
              "mean        17.048582\n",
              "std         12.706447\n",
              "min          3.000000\n",
              "25%          8.000000\n",
              "50%         14.000000\n",
              "75%         22.000000\n",
              "max        301.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRKUH4le1xo"
      },
      "source": [
        "# On to the Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY_uinnF-0co"
      },
      "source": [
        "maxlen = 60 # lengths.describe()['max'] # None to Infer it \n",
        "# maxlen: Optional Int, maximum length of all sequences. If not provided, sequences will be padded to the length of the longest individual sequence\n",
        "x_train = pad_sequences(x_train, maxlen=int(maxlen), padding='pre', truncating='pre') # prehaps pre is ideal: https://stackoverflow.com/a/51825971\n",
        "y_train = pad_sequences(y_train, maxlen=int(1), padding='pre', truncating='pre')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8GkHpsH-0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2b85b8-cd07-493b-e9f0-fb29381337bf"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import GRU, LSTM, Dense, Input, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.layers import * \n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Pf1JSFeBf1"
      },
      "source": [
        "def generate(word):\n",
        "    vocab_size = num_tokens # -1 \n",
        "\n",
        "    # word = clean_text(word)\n",
        "    inputs = np.zeros((1, 1))\n",
        "    inputs[0, 0] = word2idx[word]\n",
        "    count = 1\n",
        "    while count <= 15:\n",
        "        pred = model.predict(inputs)\n",
        "        word = np.argmax(pred)\n",
        "        if word >= vocab_size:\n",
        "            word = vocab_size - 1\n",
        "\n",
        "        inputs[0, 0] = word\n",
        "        \n",
        "        print(idx2word[word], end=\" \")\n",
        "        count += 1\n",
        "\n",
        "def on_epoch_end(epoch, word = \"life\"):\n",
        "    word = \"life\"\n",
        "    generate(word)\n",
        "    print()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyn7ULrweBff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "8543f7e7-5c3a-443c-c9b9-7f52f78320c7"
      },
      "source": [
        "path_to_glove_file = os.path.join(\"glove.6B.100d.txt\")\r\n",
        "\r\n",
        "embeddings_index = {}\r\n",
        "with open(path_to_glove_file) as f:\r\n",
        "    for line in f:\r\n",
        "        word, coefs = line.split(maxsplit=1)\r\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\r\n",
        "        embeddings_index[word] = coefs\r\n",
        "\r\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c2f6f58813ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_glove_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK01uVg3xcm9"
      },
      "source": [
        "# type(tokenizer.index_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vk9y788eTs2"
      },
      "source": [
        "num_tokens = len(tokenizer.word_index) + 2\r\n",
        "embedding_dim = 100\r\n",
        "hits = 0\r\n",
        "misses = 0\r\n",
        "\r\n",
        "# Prepare embedding matrix\r\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\r\n",
        "for i, word in tokenizer.index_word.items():\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        # Words not found in embedding index will be all-zeros.\r\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\r\n",
        "        embedding_matrix[i] = embedding_vector\r\n",
        "        hits += 1\r\n",
        "    else:\r\n",
        "        misses += 1\r\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmIVW1RKePk0"
      },
      "source": [
        "print(x_train[0])\r\n",
        "print(y_train[0])\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "\r\n",
        "x_train = np.reshape(x_train, (-1, maxlen, 1))\r\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaEAkQ1T-0dE"
      },
      "source": [
        "# vocab_size = len(tokenizer.word_index) + 1 # 8526 for eminem; ~2000 for X\n",
        "\n",
        "bridge = int(embedding_dim/3)\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False) # mask_zero=True\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(embedding_layer) # (batch_size, input_length) - > (batch_size, input_length, output_dim) \n",
        "model.add((Bidirectional(LSTM(30, return_sequences=False, recurrent_regularizer=l2(0.01))))) # (timesteps, n_features)\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Dense(bridge)) # I found this to work well in LSTMs for regression\n",
        "# model.add(GaussianNoise(0.2))\n",
        "# model.add(Bidirectional(LSTM(bridge, return_sequences=True)))\n",
        "\n",
        "model.add(Dense(int(y_train.shape[1]/2)))\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "opt = Adam() \n",
        "# Adam(0.001) is default\n",
        "# SGD(0.01) is default\n",
        "model.compile(optimizer=opt, loss=CategoricalCrossentropy(from_logits=True)) # normally, I would have this set to false, and have my output layer have h <- sigmoid; were h is the activation function\n",
        "\n",
        "best = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-afmZUd-0dL"
      },
      "source": [
        "gc.collect()\n",
        "# y_train.shape\n",
        "history = model.fit(x_train, y_train, epochs=1, batch_size=256, verbose=1, callbacks=[best, print_callback], validation_split=0.50).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF9Z5xlkQ3Nm"
      },
      "source": [
        "# model.save(\"model_BiLstm_Harry_potter.h5\")\n",
        "#model = load_model(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQoTjmtY-0dh"
      },
      "source": [
        "vocab_size = num_tokens\r\n",
        "word = clean_text(\"sat\")\r\n",
        "inputs = np.zeros((1, 1))\r\n",
        "inputs[0, 0] = word2idx[word]\r\n",
        "print(inputs)\r\n",
        "\r\n",
        "pred = model.predict(inputs)\r\n",
        "word = np.argmax(pred)\r\n",
        "\r\n",
        "idx2word[word]\r\n",
        "count = 1\r\n",
        "while count <= 15:\r\n",
        "    pred = model.predict(inputs)\r\n",
        "    word = np.argmax(pred)\r\n",
        "    if word >= vocab_size:\r\n",
        "        word = vocab_size - 1\r\n",
        "\r\n",
        "    inputs[0, 0] = word\r\n",
        "    \r\n",
        "    print(idx2word[word], end=\" \")\r\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWoOF4cwkp3l"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(history['loss'])), history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7oEhWaTz0V-"
      },
      "source": [
        "# model.compile(optimizer=opt, loss=SparseCategoricalCrossentropy(from_logits=True)) # normally, I would have this set to false, and have my output layer have h <- sigmoid; were h is the activation function\r\n",
        "# history = model.fit(x_train, y_train, epochs=3, batch_size=256, verbose=1, callbacks=[best, print_callback], validation_split=0.1).history\r\n",
        "# generate(\"the\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMKh25LdeBgA"
      },
      "source": [
        "## Try A Hidden Markov Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZs8QMz3NxvD"
      },
      "source": [
        "!pip install hmmlearn pomegranate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU17FZhR_-j8"
      },
      "source": [
        "from hmmlearn.hmm import MultinomialHMM\n",
        "print(len(tokenizer.word_index)) # vocab size? \n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9KiixB0_-_c"
      },
      "source": [
        "hmm = MultinomialHMM(n_components=10, n_iter = 100) # covariance_type=\"full\"\n",
        "hmm.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDB9wpNvEtcj"
      },
      "source": [
        "generated, y  = hmm.sample(20)  # np.array([1,2,3]).reshape(-1, 1)\n",
        "generated = generated.flatten()\n",
        "print(generated)\n",
        "\n",
        "for pred in generated:\n",
        "  print(idx2word[pred], end =' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHMAwdCoeBgF"
      },
      "source": [
        "### Train on 1D representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehvRLYh_E-ES"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_train.flatten().shape)\n",
        "\n",
        "hmm = MultinomialHMM(n_components=10, n_iter = 300) # covariance_type=\"full\"\n",
        "hmm.fit(x_train.flatten().reshape(-1, 1)) # max: 60000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqCOAZUpXfBv"
      },
      "source": [
        "generated, y = hmm.sample(20)  # np.array([1,2,3]).reshape(-1, 1)\n",
        "generated = generated.flatten()\n",
        "print(generated)\n",
        "for pred in generated:\n",
        "  print(idx2word[pred], end =' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPPAuXfKeBgJ"
      },
      "source": [
        "## Try the package [Pomegranate](https://pomegranate.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwA7Q5WneBgJ"
      },
      "source": [
        "from pomegranate import *\n",
        "\n",
        "data_sample = x_train[:10]\n",
        "data_sample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE1pZ779eBgL"
      },
      "source": [
        "model = MarkovNetwork.from_samples(data_sample, n_jobs = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RIRASFleBgM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V207Xbq3eBgQ"
      },
      "source": [
        "# model = BayesianNetwork.from_samples(data_sample, n_jobs = 3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgSPeAwTeBgR"
      },
      "source": [
        "model.predict(data_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGpH9MoWeBgT"
      },
      "source": [
        "# MultivariateGaussianDistribution will cause crash. may data is the worng shape\n",
        "# model = HiddenMarkovModel.from_samples(distribution = TODO, X= data_sample, n_components = 5, max_iterations=1)\n",
        "# model.bake()\n",
        "# model.fit(data_sample)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsHduTTTeBgV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP6wGzQ4FbMI"
      },
      "source": [
        "#### Debuging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIrKHW4WHswT"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DARIusabIPMh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OHpZuGwb_1k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}